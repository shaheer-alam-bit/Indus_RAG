{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11419681,"sourceType":"datasetVersion","datasetId":7151941},{"sourceId":11436976,"sourceType":"datasetVersion","datasetId":7163922}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install langchain_community\n# !pip install faiss-gpu\n# !pip install rank_bm25 \n# !pip install ragas\n# !pip install datasets\n# !pip install pdfplumber","metadata":{"_uuid":"68888433-599e-47af-87f9-757373d26409","_cell_guid":"43b6e81c-ee35-4ed7-ae06-713326188627","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T17:04:40.011514Z","iopub.execute_input":"2025-04-17T17:04:40.011702Z","iopub.status.idle":"2025-04-17T17:04:40.015690Z","shell.execute_reply.started":"2025-04-17T17:04:40.011683Z","shell.execute_reply":"2025-04-17T17:04:40.014830Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nos.getcwd()","metadata":{"_uuid":"df2e31d9-345e-4152-ac3e-5118926cf9dd","_cell_guid":"b9c8878b-d3a8-499e-a7ea-cf49f28c0c7a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T17:04:40.050284Z","iopub.execute_input":"2025-04-17T17:04:40.050609Z","iopub.status.idle":"2025-04-17T17:04:40.057324Z","shell.execute_reply.started":"2025-04-17T17:04:40.050576Z","shell.execute_reply":"2025-04-17T17:04:40.056334Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import pdfplumber\n\n# Open the PDF file\nwith pdfplumber.open('/kaggle/input/star-wars/Star Wars - Brotherhood Mike Chen.pdf') as pdf:\n    # Open the text file for writing\n    with open('knowledge_base.txt', 'w', encoding='utf-8') as output:\n        # Iterate over pages 10 to 349 (0-indexed, so subtract 1)\n        for i in range(9, 349):  # Page 10 is index 9\n            page = pdf.pages[i]\n            text = page.extract_text() or \"\"  # Handle cases where text is None\n            output.write(text + '\\n')  # Write text to file with a newline","metadata":{"_uuid":"4246a54e-639f-4dec-9177-350de1f09f7b","_cell_guid":"9dbfc945-e02c-4924-98b6-6deb22373da0","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T17:04:40.058534Z","iopub.execute_input":"2025-04-17T17:04:40.058828Z","iopub.status.idle":"2025-04-17T17:05:08.499663Z","shell.execute_reply.started":"2025-04-17T17:04:40.058793Z","shell.execute_reply":"2025-04-17T17:05:08.499040Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from langchain_community.document_loaders import PyMuPDFLoader\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import FAISS\nfrom langchain.schema.document import Document\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.document_loaders import TextLoader\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom transformers import pipeline\nfrom rank_bm25 import BM25Okapi\nimport numpy as np\nimport warnings\n\nfrom datasets import Dataset\nwarnings.filterwarnings(\"ignore\")\nimport textwrap","metadata":{"_uuid":"34cb9fbe-9978-425b-a29c-6c3e47364e6d","_cell_guid":"895bea96-8c84-452e-9ed0-3bb498203722","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T17:05:08.500838Z","iopub.execute_input":"2025-04-17T17:05:08.501245Z","iopub.status.idle":"2025-04-17T17:05:16.315178Z","shell.execute_reply.started":"2025-04-17T17:05:08.501220Z","shell.execute_reply":"2025-04-17T17:05:16.314393Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# 1. Load your text files\nfile_paths = [\"/kaggle/working/knowledge_base.txt\"]\ndocuments = []\n\nfor file_path in file_paths:\n    loader = TextLoader(file_path)\n    docs = loader.load()\n    documents.extend(docs)\n\n# 2. Define chunking parameters\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,        # You can try 100, 250, 512, etc.\n    chunk_overlap=256       # Try 0, 50, 100, etc.\n)\n\n# 3. Split the documents\nchunks = text_splitter.split_documents(documents)\n\n\n# 4. Output result\nprint(f\"Total chunks: {len(chunks)}\")\nprint(f\"First chunk content:\\n{chunks[0].page_content}\")\n\n# Optional: Save the chunks to a file\nwith open(\"chunked_output.txt\", \"w\", encoding='utf-8') as f:\n    for i, chunk in enumerate(chunks):\n        f.write(f\"--- Chunk {i + 1} ---\\n\")\n        f.write(chunk.page_content + \"\\n\\n\")","metadata":{"_uuid":"6778484e-9b56-40fd-8967-d8eec65ea1d2","_cell_guid":"3e46c168-6f57-41ee-9d80-9a6f06222a66","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T17:05:16.316561Z","iopub.execute_input":"2025-04-17T17:05:16.317331Z","iopub.status.idle":"2025-04-17T17:05:16.349611Z","shell.execute_reply.started":"2025-04-17T17:05:16.317304Z","shell.execute_reply":"2025-04-17T17:05:16.348944Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Total chunks: 785\nFirst chunk content:\nA long time ago in a galaxy far, far away….\nThe CLONE WARS have erupted. Caught off guard by the quickly\nexpanding conflict, the overwhelmed Jedi Order has rushed the\nadvancement of Padawans to better integrate into the Grand Army of the\nRepublic and assist the war effort.\nNewly promoted Jedi Knight Anakin Skywalker is increasingly torn\nbetween his growing duties to the Republic and his secret marriage to\nSenator Padmé Amidala of Naboo. With his Knighting, his mentor Obi-\nWan Kenobi has been elevated to the Jedi Council under the rank of Jedi\nMaster.\nAs dark forces push the Jedi further toward their transformation from\nguardians to soldiers, Anakin and Obi-Wan find themselves on equal\nfooting yet opposing paths, each pondering the meaning of peace and\njustice during a time of war…\nCHAPTER 1\nRUUG QUARNOM\nCato Neimoidia was a world of mist.\nHigh above that mist, cliffs and branches poked through, carved at all\nangles into immense mountainous spires. The thick stone of the planet’s\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Prepare documents and their metadata\ntexts = [chunk.page_content for chunk in chunks]\nmetadata = [chunk.metadata for chunk in chunks]\nprint(len(texts))","metadata":{"_uuid":"af625c44-ae0b-49f0-b5fa-8a5e893e1fd7","_cell_guid":"5952ff92-3356-46bb-9232-6e3d4fa1c397","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T17:05:16.350313Z","iopub.execute_input":"2025-04-17T17:05:16.350570Z","iopub.status.idle":"2025-04-17T17:05:16.355344Z","shell.execute_reply.started":"2025-04-17T17:05:16.350548Z","shell.execute_reply":"2025-04-17T17:05:16.354587Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"785\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Initialize embedding model\nembedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n\n# Create FAISS vector database\nvectordb = FAISS.from_documents(chunks, embedding_model)\n\n# Save FAISS index to disk for later use\nvectordb.save_local(\"faiss_index\")\n\n# Check the number of stored documents\nprint(f\"Number of documents in the vector store: {vectordb.index.ntotal}\")","metadata":{"_uuid":"4100184e-ffdf-42a7-9a2f-3424d9d62cca","_cell_guid":"bd5d7fe5-ef1f-476b-b7c1-6889d2109fa9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T17:05:16.356030Z","iopub.execute_input":"2025-04-17T17:05:16.356251Z","iopub.status.idle":"2025-04-17T17:05:20.317060Z","shell.execute_reply.started":"2025-04-17T17:05:16.356231Z","shell.execute_reply":"2025-04-17T17:05:20.316065Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Number of documents in the vector store: 785\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# BM25 Indexing\ntokenized_texts = [text.split() for text in texts]\nbm25 = BM25Okapi(tokenized_texts)\n\ndef reciprocal_rank_fusion(results_bm25, results_embedding, k=2):\n    scores = {}\n\n    # Use document content or metadata as the key\n    for rank, (doc, score) in enumerate(results_bm25):\n        doc_id = doc.page_content  # Or use doc.metadata.get(\"source\", \"unknown\") if available\n        scores[doc_id] = scores.get(doc_id, 0) + 1 / (rank+1) # (k + rank + 1)\n        print(\"BM25\", scores[doc_id])\n\n    for rank, (doc, score) in enumerate(results_embedding):\n        doc_id = doc.page_content  # Use the same identifier\n        scores[doc_id] = scores.get(doc_id, 0) + 1 / (rank+1) # (k + rank + 1)\n        print(\"Dense\", scores[doc_id])\n\n    return sorted(scores.items(), key=lambda x: x[1], reverse=True)\n\n\n# Extract page content and metadata properly\ndef format_response(doc):\n    return f\"Page {doc.metadata.get('page', 'Unknown')}: {doc.page_content.strip()}\"","metadata":{"_uuid":"cd1062d0-2dfe-4a6d-b452-0822dacc9463","_cell_guid":"26320b8d-fee4-4b59-8f00-06ac4a34c733","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T17:05:20.318102Z","iopub.execute_input":"2025-04-17T17:05:20.318465Z","iopub.status.idle":"2025-04-17T17:05:20.388721Z","shell.execute_reply.started":"2025-04-17T17:05:20.318428Z","shell.execute_reply":"2025-04-17T17:05:20.388108Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Retrieve function\ndef retrieve(query, k=3):\n    query_embedding = embedding_model.embed_query(query)\n    results_embedding = vectordb.similarity_search_with_score_by_vector(query_embedding, k=k)\n    results_embedding = sorted(results_embedding, key=lambda x: x[1], reverse=True)\n    \n    print(\"============Dense Embeddings=============\")\n    for doc, score in results_embedding:\n        print(f\"page {doc.metadata.get('page','Unknown')} - Score: {score:.4f} - {doc.page_content[:100]}...\")\n\n    # Get BM25 scores for all documents and sort to get top-k results\n    results_bm25 = [(idx, bm25.get_scores(query.split())[idx]) for idx in range(len(texts))]\n    results_bm25 = sorted(results_bm25, key=lambda x: x[1], reverse=True)[:k]  # Keep only top-k results\n    # Convert BM25 results to (Document, score) format\n    results_bm25_docs = [(Document(page_content=texts[idx], metadata=metadata[idx]), score) for idx, score in results_bm25]\n   \n    print(\"************BM25 Results*************\")\n    for doc, score in results_bm25_docs:\n        print(f\"page {doc.metadata.get('page','Unknown')} - Score: {score:.4f} - {doc.page_content[:100]}...\")\n    \n    # Create a lookup dictionary {document content -> Document object}\n    doc_lookup = {doc.page_content: doc for doc, _ in results_bm25_docs}\n    doc_lookup.update({doc.page_content: doc for doc, _ in results_embedding})\n\n    # Fuse results\n    fused_results = reciprocal_rank_fusion(results_bm25_docs, results_embedding)\n    \n    # Format results, ensuring document IDs are mapped back to actual Documents\n    return [format_response(doc_lookup[doc_id]) for doc_id, _ in fused_results if doc_id in doc_lookup]\n\n    #fused_results = reciprocal_rank_fusion(results_bm25, results_embedding)\n    #return [(texts[idx], metadata[idx][\"page\"] if \"page\" in metadata[idx] else \"Unknown\") for idx, _ in fused_results]","metadata":{"_uuid":"b246f6ab-cf66-46f5-a1d5-fce38f6e18b3","_cell_guid":"ffb44447-3b7d-4310-b600-de5a99812398","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T17:05:20.390860Z","iopub.execute_input":"2025-04-17T17:05:20.391073Z","iopub.status.idle":"2025-04-17T17:05:20.397544Z","shell.execute_reply.started":"2025-04-17T17:05:20.391054Z","shell.execute_reply":"2025-04-17T17:05:20.396773Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from langchain.schema import Document\n\ndef retrieve_dense(query, k=3):\n    query_embedding = embedding_model.embed_query(query)\n    results_embedding = vectordb.similarity_search_with_score_by_vector(query_embedding, k=k)\n    \n    # Optionally sort descending by score if needed\n    results_embedding = sorted(results_embedding, key=lambda x: x[1], reverse=True)\n    \n    print(\"============Dense Embeddings=============\")\n    for doc, score in results_embedding:\n        print(f\"page {doc.metadata.get('page','Unknown')} - Score: {score:.4f} - {doc.page_content[:100]}...\")\n    \n    # Return just the documents (or both doc and score if you want)\n    return [format_response(doc) for doc, _ in results_embedding]","metadata":{"_uuid":"63a91def-3040-47a8-9bdc-1172bea5908a","_cell_guid":"3550ba62-6e85-4c03-bd1c-e8219ba11566","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T17:05:20.399045Z","iopub.execute_input":"2025-04-17T17:05:20.399393Z","iopub.status.idle":"2025-04-17T17:05:20.414288Z","shell.execute_reply.started":"2025-04-17T17:05:20.399360Z","shell.execute_reply":"2025-04-17T17:05:20.413393Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# model_name = \"tiiuae/Falcon3-3B-Instruct\"\nmodel_name = \"Qwen/Qwen2.5-7B-Instruct\"\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map=\"auto\", #device_map='cuda'\n    torch_dtype=\"auto\",\n    trust_remote_code=True,\n)\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:05:20.415371Z","iopub.execute_input":"2025-04-17T17:05:20.415680Z","iopub.status.idle":"2025-04-17T17:05:27.609958Z","shell.execute_reply.started":"2025-04-17T17:05:20.415647Z","shell.execute_reply":"2025-04-17T17:05:27.608980Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a10c09c6d8841be9cb545abce7b01b6"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"import time\nstart_time = time.time()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:05:27.611115Z","iopub.execute_input":"2025-04-17T17:05:27.611464Z","iopub.status.idle":"2025-04-17T17:05:27.615048Z","shell.execute_reply.started":"2025-04-17T17:05:27.611428Z","shell.execute_reply":"2025-04-17T17:05:27.614221Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Query example\nquestion = \"What does Anakin Skywalker gifts Padmé Amidala during the night at the Uhmandasee Market and Please Explain its design?\"\nretrieved_responses = retrieve_dense(question, k=5)","metadata":{"_uuid":"38b046b2-6005-4a92-bec8-2021c337d908","_cell_guid":"1b70c557-41d8-4cd4-a333-ffc43ca79a26","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T17:05:27.616037Z","iopub.execute_input":"2025-04-17T17:05:27.616262Z","iopub.status.idle":"2025-04-17T17:05:27.640861Z","shell.execute_reply.started":"2025-04-17T17:05:27.616242Z","shell.execute_reply":"2025-04-17T17:05:27.640062Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"============Dense Embeddings=============\npage Unknown - Score: 1.0223 - of personal tics—the way her inhale quickened, the way her eyebrow rose,\nthe way her head turned to ...\npage Unknown - Score: 1.0109 - But in this moment, he didn’t need to. The surge of emotion that came\nwith those words was enough fo...\npage Unknown - Score: 1.0080 - materials and put her hand on the biometric reader. “Or perhaps more than a\nstatement.” It beeped an...\npage Unknown - Score: 0.9601 - Amidala appeared. Despite the bright colors of the hologram, her exquisite\npurple dress’s finely det...\npage Unknown - Score: 0.9423 - up to show him, but he failed to catch anything special about it.\nIt appeared to be just what it was...\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# # Query processing\n# question = \"What was the cause of the bombing on Cato Neimoidia in Brotherhood?\"\n# retriever = vectordb.as_retriever(search_kwargs={\"k\": 10})\n# docs = retriever.get_relevant_documents(question)\n\n# # Print results\n# for i, doc in enumerate(docs, 1):\n#     page_number = doc.metadata.get('page', 'Unknown')\n#     # print(f\"Document {i} - Page {page_number} - Score: {doc.metadata.get('score', 'N/A')}\")\n#     print(doc.page_content[:])  # Print first 500 characters of each result\n#     print(\"-\" * 80)","metadata":{"_uuid":"90c17a63-baee-4377-999f-c9e67e757b8b","_cell_guid":"0b133bdd-5159-4c97-926e-6052d40a66be","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T17:05:27.641766Z","iopub.execute_input":"2025-04-17T17:05:27.642062Z","iopub.status.idle":"2025-04-17T17:05:27.645459Z","shell.execute_reply.started":"2025-04-17T17:05:27.642031Z","shell.execute_reply":"2025-04-17T17:05:27.644643Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Create a pipeline\ngenerator = pipeline(\n\"text-generation\",\nmodel=model,\ntokenizer=tokenizer,\nreturn_full_text=False,\nmax_new_tokens=5000,\ndo_sample=False\n)","metadata":{"_uuid":"e1f46040-0335-4ea2-8e7f-7e341883074a","_cell_guid":"abed833f-9cf3-40e3-9266-44e8c25e4750","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T17:05:27.646556Z","iopub.execute_input":"2025-04-17T17:05:27.646797Z","iopub.status.idle":"2025-04-17T17:05:27.657777Z","shell.execute_reply.started":"2025-04-17T17:05:27.646775Z","shell.execute_reply":"2025-04-17T17:05:27.657113Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# !pip install sumy","metadata":{"_uuid":"d6609be4-cf01-4f88-815e-a6f0b2a111fa","_cell_guid":"c1744097-fdb6-416a-831c-505e8b82499e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T17:05:27.658491Z","iopub.execute_input":"2025-04-17T17:05:27.658678Z","iopub.status.idle":"2025-04-17T17:05:27.667622Z","shell.execute_reply.started":"2025-04-17T17:05:27.658662Z","shell.execute_reply":"2025-04-17T17:05:27.666953Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# from sumy.parsers.plaintext import PlaintextParser\n# from sumy.nlp.tokenizers import Tokenizer\n# from sumy.summarizers.lsa import LsaSummarizer\n# import textwrap\n\n# def generate_lsa_summary(retrieved_responses, num_summary_sentence=50):\n#     # Combine the retrieved responses into one string\n#     text = \" \".join(retrieved_responses)\n    \n#     # Initialize LSA summarizer\n#     LANGUAGE = \"english\"\n#     parser = PlaintextParser.from_string(text, Tokenizer(LANGUAGE))\n#     lsa_summarizer = LsaSummarizer()\n    \n#     # Generate the summary\n#     summary = []\n#     for sentence in lsa_summarizer(parser.document, num_summary_sentence):\n#         summary.append(str(sentence))\n    \n#     # Join the summarized sentences and wrap them for better readability\n#     summarized_text = \" \".join(summary)\n#     return textwrap.fill(summarized_text, 100)\n\n# summarized_responses = generate_lsa_summary(retrieved_responses)","metadata":{"_uuid":"d0f9c791-7b6c-4476-9840-8995d9479cd6","_cell_guid":"fe1f8113-5b96-41de-9d30-6988762c2b16","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T17:05:27.668416Z","iopub.execute_input":"2025-04-17T17:05:27.668660Z","iopub.status.idle":"2025-04-17T17:05:27.678832Z","shell.execute_reply.started":"2025-04-17T17:05:27.668640Z","shell.execute_reply":"2025-04-17T17:05:27.678138Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def reorder_sorted_responses(sorted_responses):\n    # Alternate between most important (edges) and least important (center)\n    most_important = sorted_responses[::2]  # Take every other response starting with the first\n    least_important = sorted_responses[1::2]  # Take every other response starting with the second\n\n    # Merge: Place least important in the center\n    reordered_responses = []\n    while most_important or least_important:\n        if most_important:\n            reordered_responses.append(most_important.pop(0))  # Add from most important\n        if least_important:\n            reordered_responses.append(least_important.pop())  # Add from least important\n    \n    return reordered_responses\nreordered_responses = reorder_sorted_responses(retrieved_responses)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:05:27.679530Z","iopub.execute_input":"2025-04-17T17:05:27.679722Z","iopub.status.idle":"2025-04-17T17:05:27.692931Z","shell.execute_reply.started":"2025-04-17T17:05:27.679705Z","shell.execute_reply":"2025-04-17T17:05:27.692225Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# ### **Summarized Retrieved Information**:\n# {summarized_responses}\n\n# Construct the RAG prompt\nprompt = f\"\"\"\nYou are an AI assistant tasked with answering questions based on retrieved knowledge.\n\n# ### **Retrieved Information**:\n# 1. {reordered_responses[0]}\n# 2. {reordered_responses[1]}\n# 3. {reordered_responses[2]}\n# 4. {reordered_responses[3]}\n# 5. {reordered_responses[4]}\n\n### **Question**:\n{question}\n\n### **Instructions**:\n- Integrate the key points from all retrieved responses into a **cohesive, well-structured answer**.\n- If the responses are **contradictory**, mention the different perspectives.\n- If none of the retrieved responses contain relevant information, reply:\n  **\"I couldn't find a good response to your query in the database.\"**\n\"\"\"","metadata":{"_uuid":"7c42a74a-9ad9-4ec8-97fa-a708b75a9ef1","_cell_guid":"7e8189cb-6a25-4382-abe2-dcd8cc775424","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T17:05:27.693681Z","iopub.execute_input":"2025-04-17T17:05:27.693988Z","iopub.status.idle":"2025-04-17T17:05:27.704008Z","shell.execute_reply.started":"2025-04-17T17:05:27.693957Z","shell.execute_reply":"2025-04-17T17:05:27.703131Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# for i in range(0,len(retrieved_responses)):\n#     print(retrieved_responses[i])\n#     print(\"-------\")","metadata":{"_uuid":"92ae01f0-4b95-4661-bcdb-81836eb470cd","_cell_guid":"7378cecd-7fe4-4549-b482-719440822f1b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T17:05:27.704886Z","iopub.execute_input":"2025-04-17T17:05:27.705131Z","iopub.status.idle":"2025-04-17T17:05:27.716245Z","shell.execute_reply.started":"2025-04-17T17:05:27.705099Z","shell.execute_reply":"2025-04-17T17:05:27.715562Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Use Qwen2.5 3B with the correct message format\nmessages = [\n    {\"role\": \"user\", \"content\": prompt}\n]\n\n# Generate output using the model\noutput = generator(messages)\n\n# Print formatted response\nprint(textwrap.fill(output[0][\"generated_text\"], width=80))","metadata":{"_uuid":"def30c04-baf3-44ee-9960-1c28fff493ae","_cell_guid":"592eda98-f21c-4c0d-89d7-8c1775908903","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T17:05:27.716975Z","iopub.execute_input":"2025-04-17T17:05:27.717252Z","iopub.status.idle":"2025-04-17T17:05:47.324482Z","shell.execute_reply.started":"2025-04-17T17:05:27.717222Z","shell.execute_reply":"2025-04-17T17:05:47.323644Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"I couldn't find a good response to your query in the database regarding the\nspecific gift Anakin Skywalker gave Padmé Amidala during the night at the\nUhmandasee Market and its design. The provided information does not include\ndetails about such a gift or its design. However, the text does provide insight\ninto Padmé's observational skills and empathetic nature, which are qualities\nthat might influence how she perceives and values gifts. For instance, Padmé\nnotices the well-being of individuals and their circumstances, suggesting that\nany gift she receives would likely be appreciated for its thoughtfulness and the\ncare behind it rather than just its material value.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"end_time = time.time()\ntime_taken = end_time - start_time\nprint(time_taken)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:05:47.325346Z","iopub.execute_input":"2025-04-17T17:05:47.325668Z","iopub.status.idle":"2025-04-17T17:05:47.330333Z","shell.execute_reply.started":"2025-04-17T17:05:47.325634Z","shell.execute_reply":"2025-04-17T17:05:47.329525Z"}},"outputs":[{"name":"stdout","text":"19.714205741882324\n","output_type":"stream"}],"execution_count":22}]}